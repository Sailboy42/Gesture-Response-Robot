{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2faf79c-e355-451b-8469-24745d852a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: mediapipe-model-maker in ./.venv/lib/python3.10/site-packages (0.2.1.4)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (1.4.0)\n",
      "Requirement already satisfied: mediapipe>=0.10.0 in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (0.10.21)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (1.26.4)\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (4.11.0.86)\n",
      "Requirement already satisfied: tensorflow<2.16,>=2.10 in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-addons in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (0.23.0)\n",
      "Requirement already satisfied: tensorflow-datasets in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (4.9.9)\n",
      "Requirement already satisfied: tensorflow-hub in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-model-optimization<0.8.0 in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (0.7.5)\n",
      "Requirement already satisfied: tensorflow-text in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (2.15.0)\n",
      "Requirement already satisfied: tf-models-official<2.16.0,>=2.13.2 in ./.venv/lib/python3.10/site-packages (from mediapipe-model-maker) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.25.8)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.15.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.14.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in ./.venv/lib/python3.10/site-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.10)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.32.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.4)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.9)\n",
      "Requirement already satisfied: attrs>=18.2.0 in ./.venv/lib/python3.10/site-packages (from dm-tree~=0.1.1->tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (25.4.0)\n",
      "Requirement already satisfied: Cython in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.2.2)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (12.0.0)\n",
      "Requirement already satisfied: gin-config in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.187.0)\n",
      "Requirement already satisfied: immutabledict in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.2)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.4.5)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.10.8)\n",
      "Requirement already satisfied: oauth2client in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.11.0.86)\n",
      "Requirement already satisfied: pandas>=0.22.0 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.3.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (7.1.3)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n",
      "Requirement already satisfied: pycocotools in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.10)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.3)\n",
      "Requirement already satisfied: sacrebleu in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.5.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.15.3)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.1)\n",
      "Requirement already satisfied: seqeval in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.2.2)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./.venv/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in ./.venv/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.72.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.26.1)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in ./.venv/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.2.5)\n",
      "Requirement already satisfied: bleach in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n",
      "Requirement already satisfied: text-unidecode in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.67.1)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n",
      "Requirement already satisfied: jax in ./.venv/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.34)\n",
      "Requirement already satisfied: jaxlib in ./.venv/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.34)\n",
      "Requirement already satisfied: opencv-contrib-python in ./.venv/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.11.0.86)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in ./.venv/lib/python3.10/site-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.3.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./.venv/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.23)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in ./.venv/lib/python3.10/site-packages (from tensorflow-hub->mediapipe-model-maker) (2.15.1)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.9)\n",
      "Requirement already satisfied: portalocker in ./.venv/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.2.0)\n",
      "Requirement already satisfied: regex in ./.venv/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.venv/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.6)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.10/site-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in ./.venv/lib/python3.10/site-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.6.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in ./.venv/lib/python3.10/site-packages (from tensorflow-addons->mediapipe-model-maker) (2.13.3)\n",
      "Requirement already satisfied: array_record>=0.5.0 in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n",
      "Requirement already satisfied: etils>=1.6.0 in ./.venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.13.0)\n",
      "Requirement already satisfied: promise in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (22.0.0)\n",
      "Requirement already satisfied: simple_parsing in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (1.13.1)\n",
      "Requirement already satisfied: toml in ./.venv/lib/python3.10/site-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
      "Requirement already satisfied: einops in ./.venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (0.8.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2025.12.0)\n",
      "Requirement already satisfied: importlib_resources in ./.venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.5.2)\n",
      "Requirement already satisfied: zipp in ./.venv/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.23.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in ./.venv/lib/python3.10/site-packages (from simple_parsing->tensorflow-datasets->mediapipe-model-maker) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!pip install --upgrade pip\n",
    "!pip install mediapipe-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f8524b-ac7b-4aab-99a2-1026476c8c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 15:14:00.531601: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-14 15:14:00.534373: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-14 15:14:00.571874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-14 15:14:00.571897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-14 15:14:00.573126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-14 15:14:00.579519: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-14 15:14:00.580195: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/oth624/mp_gesture_custom/.venv/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "2025-12-14 15:14:01.461251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/oth624/mp_gesture_custom/.venv/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from mediapipe_model_maker import gesture_recognizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333c522d-4d9a-4615-b740-2f417c53ed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mediapipe_model_maker.python.vision.gesture_recognizer' from '/home/oth624/mp_gesture_custom/.venv/lib/python3.10/site-packages/mediapipe_model_maker/python/vision/gesture_recognizer/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f06180a-44ae-4531-b4bd-994b64b40e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesture_dataset\n",
      "['rock', 'like', 'one', 'palm', 'iloveyou', 'middle_finger', 'fist', 'dislike', 'none']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"gesture_dataset\"\n",
    "\n",
    "print(dataset_path)\n",
    "labels = []\n",
    "for i in os.listdir(dataset_path):\n",
    "  if os.path.isdir(os.path.join(dataset_path, i)):\n",
    "    labels.append(i)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c0fbd3-f309-41f4-8845-bf65483e8fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52511/3727653490.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "NUM_EXAMPLES = 5\n",
    "\n",
    "for label in labels:\n",
    "  label_dir = os.path.join(dataset_path, label)\n",
    "  example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n",
    "  fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n",
    "  for i in range(NUM_EXAMPLES):\n",
    "    axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n",
    "    axs[i].get_xaxis().set_visible(False)\n",
    "    axs[i].get_yaxis().set_visible(False)\n",
    "  fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n",
    "\n",
    "plt.plot([1, 2, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19625a35-4302-4661-9a4c-bb7bbde18a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590c2d6-6c0f-48d3-b5bf-64ba40e9f60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
      "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/ab98916c-3f6c-4490-9c67-f2e3e986b2a8.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/fist/9d6402b8-04a7-4ddc-b9f4-d61326892fdf.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/ab97f84c-352d-4e38-b356-5a6ec5a33980.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/ee560a48-7920-47e2-8c28-24c0a83bb27d.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/43b161f7-30d9-4ad6-8348-43f414da2e98.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765743245.436443   52511 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1765743245.440096   52986 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) Graphics (RPL-S)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1765743245.480889   52988 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765743245.500128   52999 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765743245.549972   53018 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/7e3a9006-681d-4fca-ad78-3b7d2e78c236.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/fdbe8ace-1d05-49c6-9d1d-a071e9156968.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/2ffe2337-1a90-4c98-aa69-e0930abdb1c7.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T123450-100_jpg.rf.857c2b7b82cee0554e8d65f8211c8f44.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/53464f04-fd03-43b9-8c0a-7eb000c9658e.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/1efa49b3-8fe9-4e6a-adb2-6e67b3466971.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/3ee89362-b958-4e1b-902f-2ed0f4e9b650.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-02T171223-272_jpg.rf.3c2a4f8ca8fed6d15da0a8e71c5e74d2.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/30f2b411-7ad0-4278-a9c5-a3c0423df33a.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/0ea31549-bf4b-41b5-a3fc-d37a89780088.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/c2b22712-8140-4d7b-a699-8f19658591ef.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/e65f0e54-5cf3-40c9-af4a-dec7f178d20d.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/40b5177d-4346-46fd-b4d0-46e852c4a4b7.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/11573c1a-c749-4024-bd5f-c4bfe686feff.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/c758ae0a-712c-413d-ae04-c57a850a377e.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-02T171225-964_jpg.rf.8b162c5d499860e7b6e5aded5300aaf4.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-15-_png_jpg.rf.b0b1a9a3a87cb4a076a61dfe6975a03d.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/0a851908-474d-4033-aff5-c97628b274bd.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/f2d39804-2ef5-483b-9510-3771d1abe0e8.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/d67a4bc3-ca85-4a64-9e2b-8fe400d62013.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/56b4ddaf-7042-4931-abf5-1202fe3236d2.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T124555-397_jpg.rf.333cefd85b3e68fa7253191e254271d4.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/83d1dba4-1de7-426a-b555-f81be655e23e.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/fist/7f3c84ff-f9b2-49c2-b6f2-c539cb0484a6.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/bc382c48-9acd-4456-a2d5-73998b5662ba.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/a18c2419-5804-4f4d-92b8-6d436f1fb548.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/49f001f1-fe3a-4018-b2da-01895d570515.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/b525ddf0-b25f-4713-96db-d7fa68650588.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/e1c05742-03f5-4bd0-8d42-43c1abb1f86f.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T123448-566_jpg.rf.5f4cf41555baf2dbef732a63f059d4cf.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/3b1cee4c-6e25-48f8-a6b2-560ca9bd31b1.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/4130274a-ec7a-4f7b-99de-fb8efebff418.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/cd9f4786-1d8e-45dc-b64c-d464863feb5c.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/4eb585df-c65f-40a9-868c-7d4cf5ab415b.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/153155cd-0d87-4e4e-8478-6f4f0ffc4fea.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/e67f3562-53c0-42ce-b2da-8e94ccf5e0db.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/1a689651-be41-4ac0-a8eb-73e92d02ebff.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T123419-617_jpg.rf.564d961f22d6d2e88c3c18cde0ce6631.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/76a4a67f-b5bf-4a5d-a5cf-b2abfe9f907c.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/b2b1a1a5-1155-4fde-b98c-2faa75791021.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/62521d04-1ea5-4a32-9764-4c205b343bbd.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/51f005e7-b2b1-4037-a64c-4e11bb1522f9.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/ee9b927d-8abd-4e39-b4fc-a6b198bafa8b.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/0f07ee23-37ab-4e91-bee1-0eca85f4a9df.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/f8e5f620-d816-434a-9c39-b80bf5899840.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/fe2e1547-3aee-4314-bae0-0efba872c21d.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/0733a895-1035-4d2a-bef7-d19dc32c8021.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/f7bbe2d2-9350-4c40-8af4-c25d8a126695.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/b92b4d4c-706e-4684-9aba-3225a9a340b6.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/035e36bf-fc80-4179-9698-2de2a80bb8a4.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T124606-008_jpg.rf.3d09665b00ed8fedc389f98644bb1fb8.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/1596c141-ab75-4d79-aa82-09c5439f1b84.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/6a7dd98d-e34c-41ec-b37d-a7c9028bd03b.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/cf32d7fd-b4c7-4c19-9960-dcef25b5ee53.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/f1091d2b-cc9f-4f57-8ae1-3c2dff6eb441.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/d6d12cd6-8601-4dc6-a314-1350bfa7e18a.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/13e3190c-d0bb-45b7-972b-12492d27385b.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/353b970a-2717-4777-a2e3-78608099b8de.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/like/9420f56d-5c55-492e-990c-d8ef5c244eee.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/db3a8a69-921f-4c01-9398-811275b9c5bb.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/48bf083f-9882-4d09-af42-ac8a0d5cdf68.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/9a0c0dee-65ec-4a17-aadd-526d9a321fc2.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/like/7651e775-9405-4588-982b-36afb5f487c4.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/ae2d11b5-fe4d-4149-83fa-aa59f423530a.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/0fadbb04-a027-49c7-862e-4df4a488e4e7.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/78da95f1-7ad9-4e6c-bb3d-5607fa633a26.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/b633b045-9546-4d79-b18d-1af590c08f28.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/6453065c-6f08-4e85-b58c-5db81c923d7a.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/one/373bdfdd-374c-49ae-a25e-c53489dd2f96.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/82a4ea93-61fd-429e-a630-c3af3dc8a3a5.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/f6b49910-5a80-457e-9052-288d1a5c2855.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/807c5485-00c3-4bea-8be1-539fcbc5ed69.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/images-2023-10-03T124107-318_jpg.rf.d208542846630caef01f3c2938af7a94.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/7ad48770-a856-4115-b445-f59f04d38ace.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/middle_finger/download-11-_jpg.rf.a409245e4340a8bcdaf482cdc6ddf89e.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/701b79c3-a636-47c3-80ec-732f025576bf.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/fist/c14337fc-80c9-41e8-81d7-ade549c2d438.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/f9787756-902d-4997-b23c-cec316bad475.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/0f6930ef-5d7b-40de-949f-6385f5782dca.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/dislike/5d5606e0-2370-4339-bb40-cc6f4c081e37.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/5ff77048-65e6-40be-b78c-23d1b072f0e5.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/c52cb4d7-4e61-4c24-b411-1cfcd0a57dd7.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/37917115-b027-43ad-89bf-ac392de98d6b.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/ba185fbb-42dc-4076-8ef7-2546a9660ada.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/rock/a552397e-4aef-4f83-8ff5-962ef42f9503.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/819c1a74-5c5e-47a1-8227-d8c28ff5ebe7.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/2047e731-44e8-4495-935f-421502095ebe.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/14e0c6b5-2983-45d0-913b-8572448e1432.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/2d89f908-62da-40e5-8fea-7e8decb4ffc1.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/like/9c66d339-8417-4222-bb42-a6bdcf3a709a.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/b5f937cb-8f6b-42cd-b3d2-4a94b0276af8.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/palm/3f0e90a2-fe47-4caf-9c77-a849709d1a4d.jpg\n",
      "INFO:tensorflow:Loading image /home/oth624/mp_gesture_custom/gesture_dataset/none/ef17cac6-a3f3-43cc-a487-1f1d5392cb2c.jpg\n"
     ]
    }
   ],
   "source": [
    "data = gesture_recognizer.Dataset.from_folder(\n",
    "    dirname=dataset_path,\n",
    "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
    ")\n",
    "\n",
    "train_data, rest_data = data.split(0.8)\n",
    "validation_data, test_data = rest_data.split(0.5)\n",
    "\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Val:\", len(validation_data))\n",
    "print(\"Test:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45abc1-44b2-4d44-b654-00293db9bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(\"Total samples:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a44e21-2512-4dca-a90b-8e9516f1c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = gesture_recognizer.HParams(export_dir=\"exported_model_gesture\")\n",
    "options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)\n",
    "model = gesture_recognizer.GestureRecognizer.create(\n",
    "    train_data=train_data,\n",
    "    validation_data=validation_data,\n",
    "    options=options\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe1dc2-0d17-4442-8fdf-8fe7c27ca74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_data, batch_size=1)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a93d23-c3e3-48cc-82c3-b0c5a069a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_model()\n",
    "!ls exported_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777e4d6-dfb7-4da1-a634-55912bb59faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.download('exported_model/gesture_recognizer.task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e9e25-b57a-4c47-a327-5c75c426f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fcf7f-963c-4931-ae7d-671e7b94d254",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hparams = gesture_recognizer.HParams(export_dir=\"exported_model_middle_finger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7eb35-a6e1-4f5a-a832-66f68d4e0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "MODEL_PATH = \"exported_model_gesture_recognizer.task\"\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "GestureRecognizer = vision.GestureRecognizer\n",
    "GestureRecognizerOptions = vision.GestureRecognizerOptions\n",
    "VisionRunningMode = vision.RunningMode\n",
    "\n",
    "# Use IMAGE mode (no callback needed)\n",
    "options = GestureRecognizerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=MODEL_PATH),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    ")\n",
    "\n",
    "recognizer = GestureRecognizer.create_from_options(options)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # try 1/2 if you have multiple cameras\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not open webcam\")\n",
    "\n",
    "print(\"Webcam running... press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Convert BGR (OpenCV) -> RGB (MediaPipe)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb_frame\n",
    "    )\n",
    "\n",
    "    result = recognizer.recognize(mp_image)\n",
    "\n",
    "    if result.gestures:\n",
    "        top = result.gestures[0][0]\n",
    "        label = f\"{top.category_name} ({top.score:.2f})\"\n",
    "        color = (0, 255, 0) if top.category_name == \"middle_finger\" else (0, 0, 255)\n",
    "    else:\n",
    "        label = \"No gesture\"\n",
    "        color = (0, 255, 255)\n",
    "\n",
    "    cv2.putText(frame, label, (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Middle Finger Detector\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
